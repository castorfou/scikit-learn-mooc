{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "c452d768",
   "metadata": {},
   "source": [
    "# üèÅ Wrap-up quiz\n",
    "\n",
    "**This quiz requires some programming to be answered.**\n",
    "\n",
    "Open the dataset `house_prices.csv` with the following command:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "330d85c0",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-06-11T07:39:32.965947Z",
     "start_time": "2021-06-11T07:39:32.769209Z"
    }
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "ames_housing = pd.read_csv(\"../datasets/house_prices.csv\", na_values=\"?\")\n",
    "target_name = \"SalePrice\"\n",
    "data = ames_housing.drop(columns=target_name)\n",
    "target = ames_housing[target_name]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a699934e",
   "metadata": {},
   "source": [
    "`ames_housing` is a pandas dataframe. The column \"SalePrice\" contains the\n",
    "target variable. Note that we instructed pandas to treat the character \"?\" as a\n",
    "marker for cells with missing values also known as \"null\" values.\n",
    "\n",
    "To simplify this exercise, we will only used the numerical features defined\n",
    "below:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "273c90bd",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-06-11T07:40:14.315308Z",
     "start_time": "2021-06-11T07:40:14.311039Z"
    }
   },
   "outputs": [],
   "source": [
    "numerical_features = [\n",
    "    \"LotFrontage\", \"LotArea\", \"MasVnrArea\", \"BsmtFinSF1\", \"BsmtFinSF2\",\n",
    "    \"BsmtUnfSF\", \"TotalBsmtSF\", \"1stFlrSF\", \"2ndFlrSF\", \"LowQualFinSF\",\n",
    "    \"GrLivArea\", \"BedroomAbvGr\", \"KitchenAbvGr\", \"TotRmsAbvGrd\", \"Fireplaces\",\n",
    "    \"GarageCars\", \"GarageArea\", \"WoodDeckSF\", \"OpenPorchSF\", \"EnclosedPorch\",\n",
    "    \"3SsnPorch\", \"ScreenPorch\", \"PoolArea\", \"MiscVal\",\n",
    "]\n",
    "\n",
    "data_numerical = data[numerical_features]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3988589f",
   "metadata": {},
   "source": [
    "We will compare the statistical performance of a decision tree and a linear\n",
    "regression. For this purpose, we will create two separate predictive models\n",
    "and evaluate them by 10-fold cross-validation.\n",
    "\n",
    "Thus, use `sklearn.linear_model.LinearRegression` and\n",
    "`sklearn.tree.DecisionTreeRegressor` to create the model. Use the default\n",
    "parameters for both models.\n",
    "\n",
    "**Note**: missing values should be handle with a scikit-learn\n",
    "`sklearn.impute.SimpleImputer` and the default strategy (`\"mean\"`). Be also\n",
    "aware that a linear model requires to scale the data. You can use a\n",
    "`sklearn.preprocessing.StandardScaler`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "b45c4ef3",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-06-11T07:49:07.838101Z",
     "start_time": "2021-06-11T07:49:07.619679Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Score for linear model is 0.72 +/- 0.14\n",
      "Score for tree model is 0.62 +/- 0.09\n"
     ]
    }
   ],
   "source": [
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.tree import DecisionTreeRegressor\n",
    "\n",
    "from sklearn.pipeline import make_pipeline\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.impute import SimpleImputer\n",
    "\n",
    "from sklearn.model_selection import cross_validate\n",
    "\n",
    "linear_model = make_pipeline(StandardScaler(), SimpleImputer(), LinearRegression())\n",
    "tree_model = make_pipeline(SimpleImputer(), DecisionTreeRegressor())\n",
    "\n",
    "linear_cv_result = cross_validate(linear_model, data_numerical, target, cv=10, return_estimator=True, scoring='r2')\n",
    "print(f'Score for linear model is {linear_cv_result[\"test_score\"].mean():0.2f} +/- {linear_cv_result[\"test_score\"].std():0.2f}')\n",
    "\n",
    "tree_cv_result = cross_validate(tree_model, data_numerical, target, cv=10, return_estimator=True, scoring='r2')\n",
    "print(f'Score for tree model is {tree_cv_result[\"test_score\"].mean():0.2f} +/- {tree_cv_result[\"test_score\"].std():0.2f}')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ca354a70",
   "metadata": {},
   "source": [
    "# Question 1\n",
    "Is the decision tree model better in terms of $R^2$ score than the linear\n",
    "regression?\n",
    "\n",
    "- a) Yes\n",
    "- b) No\n",
    "\n",
    "_Select a single answer_"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c8c17579",
   "metadata": {},
   "source": [
    "Instead of using the default parameter for decision tree regressor, we will\n",
    "optimize the depth of the tree. Using a grid-search\n",
    "(`sklearn.model_selection.GridSearchCV`) with a 10-fold cross-validation,\n",
    "answer to the questions below. Vary the `max_depth` from 1\n",
    "level up to 15 levels."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "5e2db03e",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-06-11T07:53:42.173857Z",
     "start_time": "2021-06-11T07:53:42.170153Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'memory': None,\n",
       " 'steps': [('simpleimputer', SimpleImputer()),\n",
       "  ('decisiontreeregressor', DecisionTreeRegressor())],\n",
       " 'verbose': False,\n",
       " 'simpleimputer': SimpleImputer(),\n",
       " 'decisiontreeregressor': DecisionTreeRegressor(),\n",
       " 'simpleimputer__add_indicator': False,\n",
       " 'simpleimputer__copy': True,\n",
       " 'simpleimputer__fill_value': None,\n",
       " 'simpleimputer__missing_values': nan,\n",
       " 'simpleimputer__strategy': 'mean',\n",
       " 'simpleimputer__verbose': 0,\n",
       " 'decisiontreeregressor__ccp_alpha': 0.0,\n",
       " 'decisiontreeregressor__criterion': 'mse',\n",
       " 'decisiontreeregressor__max_depth': None,\n",
       " 'decisiontreeregressor__max_features': None,\n",
       " 'decisiontreeregressor__max_leaf_nodes': None,\n",
       " 'decisiontreeregressor__min_impurity_decrease': 0.0,\n",
       " 'decisiontreeregressor__min_impurity_split': None,\n",
       " 'decisiontreeregressor__min_samples_leaf': 1,\n",
       " 'decisiontreeregressor__min_samples_split': 2,\n",
       " 'decisiontreeregressor__min_weight_fraction_leaf': 0.0,\n",
       " 'decisiontreeregressor__random_state': None,\n",
       " 'decisiontreeregressor__splitter': 'best'}"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tree_model.get_params()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "5f0f6a5e",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-06-11T08:06:52.648867Z",
     "start_time": "2021-06-11T08:06:51.247811Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "GridSearchCV(cv=10,\n",
       "             estimator=Pipeline(steps=[('simpleimputer', SimpleImputer()),\n",
       "                                       ('decisiontreeregressor',\n",
       "                                        DecisionTreeRegressor())]),\n",
       "             param_grid={'decisiontreeregressor__max_depth': array([ 1,  2,  3,  4,  5,  6,  7,  8,  9, 10, 11, 12, 13, 14])},\n",
       "             scoring='r2')"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.model_selection import GridSearchCV\n",
    "import numpy as np\n",
    "\n",
    "param_grid = {\"decisiontreeregressor__max_depth\": np.arange(1, 15, 1)}\n",
    "tree_reg = GridSearchCV(tree_model, param_grid=param_grid, cv=10, scoring='r2')\n",
    "tree_reg.fit(data_numerical, target)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "48fb7abb",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-06-11T08:07:39.451497Z",
     "start_time": "2021-06-11T08:07:39.448231Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "6"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tree_reg.best_params_['decisiontreeregressor__max_depth']"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "99cf564f",
   "metadata": {},
   "source": [
    "# Question 2\n",
    "What is the optimal tree depth for the current problem?\n",
    "\n",
    "- a) The optimal depth is ranging from 3 to 5\n",
    "- b) The optimal depth is ranging from 5 to 8\n",
    "- c) The optimal depth is ranging from 8 to 11\n",
    "- d) The optimal depth is ranging from 11 to 15\n",
    "\n",
    "_Select a single answer_\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "4b4487bf",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-06-11T08:09:08.404145Z",
     "start_time": "2021-06-11T08:09:08.398015Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.7003321260890762"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tree_reg.best_score_"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "84dd4221",
   "metadata": {},
   "source": [
    "# Question 3\n",
    "A tree with an optimal depth is performing:\n",
    "\n",
    "- a) better than a linear model\n",
    "- b) equally to a linear model\n",
    "- c) worse than a linear model\n",
    "\n",
    "_Select a single answer_"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d3c25876",
   "metadata": {},
   "source": [
    "Instead of using only the numerical dataset (which was the variable\n",
    "`data_numerical`), use the entire dataset available in the variable `data`.\n",
    "\n",
    "Create a preprocessor by dealing separately with the numerical and categorical\n",
    "columns. For the sake of simplicity, we will define the categorical columns as\n",
    "the columns with an `object` data type.\n",
    "\n",
    "**Do not optimize the `max_depth` parameter for this exercise.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "bfa3dbbc",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-06-11T08:34:28.435776Z",
     "start_time": "2021-06-11T08:34:25.951657Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Score is 0.80 +/- 0.14\n",
      "Score for tree model is 0.70 +/- 0.09\n"
     ]
    }
   ],
   "source": [
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.tree import DecisionTreeRegressor\n",
    "\n",
    "from sklearn.pipeline import make_pipeline\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.impute import SimpleImputer\n",
    "\n",
    "from sklearn.model_selection import cross_validate\n",
    "\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "\n",
    "\n",
    "from sklearn.compose import make_column_selector as selector\n",
    "\n",
    "from sklearn.pipeline import Pipeline\n",
    "\n",
    "categorical_columns_selector = selector(dtype_include=object)\n",
    "categorical_columns = categorical_columns_selector(data)\n",
    "\n",
    "numeric_transformer = Pipeline(steps=[\n",
    "    ('imputer', SimpleImputer(strategy='mean')),\n",
    "    ('scaler', StandardScaler())])\n",
    "categorical_transformer = Pipeline(steps=[\n",
    "    ('imputer', SimpleImputer(strategy=\"most_frequent\", verbose=1)),\n",
    "    ('onehotencoder', OneHotEncoder(handle_unknown = 'ignore'))])\n",
    "\n",
    "linear_preprocessor = ColumnTransformer(transformers=[\n",
    "     (\"num-preprocessor\", numeric_transformer, numerical_features),\n",
    "    (\"cat-preprocessor\", categorical_transformer, categorical_columns)\n",
    "])\n",
    "\n",
    "tree_preprocessor = ColumnTransformer(transformers=[\n",
    "     (\"num-preprocessor\", SimpleImputer(), numerical_features),\n",
    "    (\"cat-preprocessor\", categorical_transformer, categorical_columns)\n",
    "])\n",
    "\n",
    "\n",
    "linear_model = make_pipeline(linear_preprocessor, LinearRegression())\n",
    "linear_cv_result = cross_validate(linear_model, data, target, cv=10, return_estimator=True, scoring='r2')\n",
    "\n",
    "print(f'Score is {linear_cv_result[\"test_score\"].mean():0.2f} +/- {linear_cv_result[\"test_score\"].std():0.2f}')\n",
    "\n",
    "\n",
    "tree_model = make_pipeline(tree_preprocessor, DecisionTreeRegressor())\n",
    "tree_cv_result = cross_validate(tree_model, data, target, cv=10, return_estimator=True, scoring='r2')\n",
    "print(f'Score for tree model is {tree_cv_result[\"test_score\"].mean():0.2f} +/- {tree_cv_result[\"test_score\"].std():0.2f}')\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "72aefd2d",
   "metadata": {},
   "source": [
    "# Question 4\n",
    "Are the performance in terms of $R^2$ better by incorporating the categorical\n",
    "features in comparison with the previous tree with the optimal depth?\n",
    "\n",
    "- a) No the statistical performance are the same: ~0.7\n",
    "- b) The statistical performance is slightly better: ~0.72\n",
    "- c) The statistical performance is better: ~0.74\n",
    "\n",
    "_Select a single answer_\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a393ed16",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.4"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": true
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
